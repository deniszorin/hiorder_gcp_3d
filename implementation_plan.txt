Implementation plan for Python

Scope and inputs
- Mesh: triangular, manifold, oriented. Faces as triples of vertex indices. Vertices as 3D positions.
Using obj format.
- Parameters: alpha (default 0.1), p (default 2), evaluation point(s) q.
- Outputs: smoothed_offset_potential(q) and optionally face/edge/vertex components.

1) Data structures and connectivity
- Parse OBJ into:
  - V: float (n,3)
  - F: int (m,3)
- Build connectivity:
  - faces_per_vertex: list of face indices for each vertex.
  - faces_per_edge: dict mapping edge (min_vi,max_vj) -> list of incident face indices.
  - edges_per_vertex: list of edges (as sorted index pairs) for each vertex.
- Validation routines:
  - Single triangle check (each edge has 1 face, each vertex has 1 face).
  - Tetrahedron checks described in implementation.txt.
  - Boundary case check (removed face) described in implementation.txt

2) Geometry helpers
- For each face:
  - n = unit normal (based on CCW vertex order).
  - For each edge e of face (oriented CCW):
    - d_e = unit edge direction (from v_i to v_{i+1}).
    - Inward edge normal = n x d_e.
- Projection:
  - P_e(q): projection of q to the line of edge e.
  - P^e(q): same as P_e(q) for edge potential.
  - r^f(q): distance to triangle plane.
  - r^e(q): distance to edge line.
  - r^v(q): distance to vertex.

3) Smoothed Heaviside
- H(z):
  - if z < -1: 0
  - if -1 <= z <= 1: ((2 - z) * (z + 1)^2) / 4
  - if z > 1: 1
- H_alpha(t) = H(t / alpha)

4) Potential components
- Face blending term:
  - Phi^{e,f}(q) = (q - P_e(q))_+ dot (n x d_e)
  - (q - P_e(q))_+ is the unit-length direction from q to P_e(q)
  - B^f(q) = product over edges e in f of H_alpha(Phi^{e,f}(q))
  - I^f(q) = B^f(q) / (r^f(q)^p)
- Edge term:
  - Default (edge_potential_mode="heaviside"):
    - Store Phi^{e,f} per face edge while computing B^f.
    - Phi^{0,e}(q) = (q - p0)_+ dot (p1 - p0)_+
    - Phi^{1,e}(q) = (q - p1)_+ dot (p0 - p1)_+
    - B^e(q) = (1 - H_alpha(Phi^{e,f0}(q)) - H_alpha(Phi^{e,f1}(q))) * H_alpha(Phi^{0,e}(q)) * H_alpha(Phi^{1,-e}(q))
    - I^e(q) = B^e(q) / (r^e(q)^p)
    - For boundary edges, treat the missing face H_alpha(Phi^{e,f}) as 0
  - Optional (edge_potential_mode="blend"):
    - B^e(q) = (1 - B^{f0}(q) - B^{f1}(q)) * H_alpha(Phi^{0,e}(q)) * H_alpha(Phi^{1,e}(q))
- Vertex term:
  - Default (vertex_potential_mode="heaviside"):
    - For face f incident to v, let e0(v,f), e1(v,f) be its two edges incident to v.
    - Face contribution: sum_f H_alpha(Phi^{e0(v,f),f}(q)) * H_alpha(Phi^{e1(v,f),f}(q))
    - For edge e incident to v, with faces f0(e), f1(e):
      - Phi^{v,e} = Phi^{0,e} if v is p0, Phi^{1,-e} if v is p1
      - Edge contribution: sum_e (1 - H_alpha(Phi^{e,f0(e)}(q)) - H_alpha(Phi^{e,f1(e)}(q))) * H_alpha(Phi^{v,e}(q))
    - B^v(q) = 1 - (face contributions) - (edge contributions)
    - I^v(q) = B^v(q) / (r^v(q)^p)
  - Optional (vertex_potential_mode="blend"):
    - B^v(q) = 1 - sum_{f in F_v} B^f(q) - sum_{e in E_v} B^e(q)
    - I^v(q) = B^v(q) / (r^v(q)^p)
- Total:
  - I(q) = sum I^f + sum I^e + sum I^v

5) Singularities
- If r^f(q), r^e(q), or r^v(q) is zero, return a large value (1e12) for that term.
- Use a small epsilon for unit vector normalization when q == P_e(q).
- Use global singular_value and eps for these thresholds.

6) Implementation flow
- Precompute per-face geometry (normals, edge directions, edge inward normals).
- Evaluate for point(s) q in smoothed_offset_potential:
  1) Loop faces: compute B^f(q) and I^f(q); store B^f.
  2) Loop edges: use incident faces to compute B^e and I^e.
  3) Loop vertices: use stored B^f and B^e to compute I^v.
  4) Sum as requested (total or components) based on include_faces/include_edges/include_vertices flags.

7) Performance
- Numpy vectorization for batched q points.
- Optional Numba JIT for inner loops (face/edge/vertex sweeps).
- Store geometry in contiguous arrays for JIT-friendly access.

8) Visualization (Plotly)
- Function A: isolines on a plane (p, n):
  - Sample grid in plane coordinates.
  - Evaluate potential at each grid point.
  - Plot contour/isolines.
- Function B: isosurface in 3D:
  - Sample 3D grid.
  - Evaluate potential (select total or face/edge/vertex via flag).
  - Plot isosurface via Plotly 3D contouring.

9) Validation scenarios
- Single face:
  - Plane perpendicular to face for isolines.
  - 3D isosurface of total potential.
- Edge shared by two triangles with non-collinear normals:
  - Plane perpendicular to edge isolines.
  - Edge potential isosurface at specified value.
- Vertex with 4 incident triangles:
  - Construct geometry as described (alternating z +/-, center z = 0).
  - Vertex potential isosurface.
- Variant: all neighbor z negative (center at 0).

Numba potential acceleration plan (smoothed_offset_potential) - detailed
1) Mirror current `smoothed_offset_potential` logic in `potential.py`:
   - Face term: uses `H_alpha(phi_ef)` product and `r_f_abs` in denominator.
   - Edge term: uses `H_alpha(phi_ve)` and per-edge face factors `H_alpha(phi_ef)`.
   - Vertex term: uses per-face and per-edge directional factors with the same formulas.
   - One-sided/localized branches need the same behavior as `outside_face/edge/vertex`.
2) Add `potential_numba.py` with Numba-friendly helpers (scalar, point-level):
   - `h_local_scalar`, `h_epsilon_scalar`, `H_scalar`, `H_alpha_scalar`.
   - Vector helpers: `safe_norm`, `unit_vec`, `project_point_to_line`.
   - Phi helpers: `phi_ef_scalar(q, p0, p1, n, edge_inward)` and
     `phi_ve_scalar(q, p0, p1)` to compute Phi^{e,f}, Phi^{v,e} inside the element functions.
   - One-sided helpers mirroring `outside_face`, `outside_edge`, `outside_vertex`:
     `outside_face_scalar`, `outside_edge_scalar`, `_vertex_face_edge_candidates_scalar`,
     `outside_vertex_scalar` (all scalar, no precomputed `PotentialTerms`).
   - To reduce recompute, pass intermediate quantities from `potential_face`,
     `potential_edge`, `potential_vertex` into their `outside_*` counterparts
     (e.g., r_f, r_e, P_e, Phi^{e,f}, Phi^{v,e}) instead of re-deriving them.
3) Add the required element/point evaluators:
   - `potential_face(q, fidx, conn, geom, alpha, p, epsilon, localized, one_sided)`.
   - `potential_edge(q, eidx, conn, geom, alpha, p, epsilon, localized, one_sided)`.
   - `potential_vertex(q, vidx, conn, geom, alpha, p, epsilon, localized, one_sided)`.
   - `smoothed_offset_potential_point(q, face_indices, conn, geom, ...)` that:
     - Sums face contributions over `face_indices`.
     - Collects unique edges/vertices referenced by those faces using marker arrays.
     - Sums edge/vertex contributions once per unique element.
4) Dataclass changes / additions:
   - Keep `MeshData`/`MeshGeometry` unchanged.
   - Add a new frozen dataclass (e.g., `NumbaConnectivity`) in `potential_numba.py`
     holding only ndarrays: `V`, `faces`, `edges`, `face_edges` (nf,3),
     `edge_faces` (ne,2 with -1 for boundary), `vertex_face_offsets/indices`
     and `vertex_edge_offsets/indices` (CSR-style).
   - If needed, add a lightweight `NumbaGeometry` dataclass that just wraps the
     existing `MeshGeometry` arrays for numba calls.
5) Build the ndarray connectivity copy inside `smoothed_offset_potential_numba`:
   - Convert `MeshData` lists (`edges`, `vertices_to_faces`, `edges_to_faces`,
     `vertices_to_edges`) into the arrays above.
   - Precompute `face_edges` to avoid `get_local_index`/edge searches.
6) Add `smoothed_offset_potential_numba` with the same signature as
   `smoothed_offset_potential`:
   - Build full `face_indices = np.arange(nf)` for now (future per-point subsets).
   - Loop over points and call `smoothed_offset_potential_point`.
7) Wire a `use_numba: bool = False` flag into `smoothed_offset_potential`
   and dispatch to `potential_numba.smoothed_offset_potential_numba`
   (no other edits to `potential.py`).
8) Tests and timing:
   - New test module compares python vs numba on meshes from
     `viz.build_validation_scenes()` and `tests/test_potential.py` helpers.
   - Use small grids (resolution determined after timing).
   - Benchmark both versions with `time.perf_counter`, report speed ratio, and
     choose grid sizes so tests stay under 3 minutes.

 
C++ potential + auto-diff plan (using CollisionMesh)
Mapping from Python MeshData/MeshGeometry to cpp::CollisionMesh (+ derived class)
- MeshData.V -> CollisionMesh::rest_positions() (Eigen::MatrixXd)
- MeshData.faces -> CollisionMesh::faces() (Eigen::MatrixXi)
- MeshData.edges -> CollisionMesh::edges() (Eigen::MatrixXi)
- MeshData.faces_to_edges -> CollisionMesh::faces_to_edges() (Eigen::MatrixXi)
- MeshData.edges_to_faces -> CollisionMesh::edges_to_faces() (Eigen::MatrixXi)
- MeshData.vertices_to_faces -> CollisionMesh::vertices_to_faces() (std::vector<std::vector<int>>)
- MeshData.vertices_to_edges -> CollisionMesh::vertices_to_edges() (std::vector<std::vector<int>>)
- MeshGeometry.normals -> new derived member (Eigen::MatrixXd, |F|x3)
- MeshGeometry.edge_inward -> new derived member (Eigen::MatrixXd or std::array per face, |F|x9)
- MeshGeometry.edge_normals -> new derived member (Eigen::MatrixXd, |E|x3)

Step 1: C++ double implementation (matches python_numba)
1) Create a derived class in a new cpp/hpp (do not modify collision_mesh.hpp/.cpp):
   - Compute/store normals, edge_inward, edge_normals from CollisionMesh data.
   - Expose accessors for the additional geometry arrays.
2) Implement C++ potential functions mirroring `potential_numba.py`:
   - potential_face, potential_edge, potential_vertex, smoothed_offset_potential_point.
   - Use CollisionMesh adjacency directly (no CSR compression).
3) Add pybind11 bindings for the C++ potential:
   - Expose a `smoothed_offset_potential_cpp(q, mesh, alpha, p, ...)`.
   - Convert numpy arrays to Eigen and build the derived mesh class in C++.
4) Add Python test module comparing C++ vs numba on the same meshes/grids:
   - Reuse validation scenes + tetrahedron + flipped cases.
5) Add a `use_cpp: bool = False` option to `smoothed_offset_potential`
   and pass it through from `isosurface_with_clip` for visual verification.
6) Validate consistency vs numba and report timing.

Step 2: Auto-diff (TinyAD)
1) Templetize the C++ potential code on scalar type `F`:
   - Keep constants (alpha, p, epsilon, eps, singular_value) and constants in the code like 1.0/2.0 as double.
   - Do not templetize outside_vertex helpers and cone_hull functions, these should remain as double. 
2) Instantiate and test for `F=double` (must match Step 1 results).
3) Instantiate and test for TinyAD autodiff scalar type:
   - Ensure potential evaluation values match numba (derivatives can be checked later).
4) Keep the Python verification tests passing unchanged.